---
slug: amalgam
status: proof
title: Amalgam
type: performance
submission_type: Performance
contributors:
- person: $hoogland-timo
- person: $freeke-saskia
---

# $PROGRAM_NOTE

Amalgam is an audiovisual live coded performance by Sasj & Timo of algorithmic electronic dance music and playful geometry and patterns. The work is the latest iteration in an ongoing research and collaboration between Saskia Freeke and Timo Hoogland where they explore the possible relationships between image and sound. During this piece the visual output is used as input for sonic transformations, displacing rhythm, melody and sonic textures based on color, geometry and patterns.

# $ABSTRACT

For the Algorave we propose our duo performance, titled Amalgam, combining audio (live coded by Timo Hoogland) and visuals (live coded by Saskia Freeke). The performance is a result of our ongoing research in exploring the relationship between sound and visuals. During the performance we use the visuals as a means to displace and generate musical information such as rhythms, melodies and spectral transformations. With this approach we explore ways to let music react to visual input as opposed to the more common practice of making visuals react to sound. Our research started out from our mutual interest to have visuals not only as receiver of the sound, but also have it influence the sound in a feedback loop. The visuals from Saskia Freeke are send via a network to Timo Hoogland’s computer. From there the visuals are analysed in rows for color (hue) and intensity (lightness). The analysis results in lists of values that are considered as sequences that can be mapped to many parameters of the musical instruments. This approach is inspired by the composition method of total serialism, which stems from the 1920’s twelve-tone technique, in which every aspect of a composition is expressed as separate series of values in pitch, rhythm, timbre and more. The final result is an audiovisual piece where sound and image are intertwined and the audience is encouraged to listen and look for the patterns and connections. The environments used for the performance are Mercury, Hydra and Flok. Mercury is a live coding environment designed by Timo Hoogland that focusses on quick expression of musical ideas for electronic music. Hydra is a browser-based live code-able video synth and coding environment developed by Olivia Jack. The syntax is inspired by analog modular synthesis, in which chaining a set of transformations together generates visual patterns. Flok is a web-based collaborative editor designed by Damián Silvani.

**(an image must still be included here)**